I think that this project was largely successful. I had a very solid idea of what specific functions I needed to complete it effectively, and I followed it with only minor modifications. The only frustrating part was probably cleaning up the source text; keeping punctuation in the list of words meant that I had to catch all cases of “exeunt” or character speech with different combinations of brackets and other punctuation to make sure I caught all cases (and I still have occasional instances of these). In addition, the rhyming function of the couplet program was particularly tough, because I wrote it myself using build-in string operations.

I was surprised at how versatile my resulting code was, because I could apply more or less the same operations to Hamlet, Hamilton, and Trump speeches with a few minor modifications. This is probably a useful attribute of any program that I could write; to have it able to be used for several applications.Because my several programs work in largely the same way, I will describe my implementation in the context of my “Hamleton” synthesis program. After processing both texts to remove things like character names, stage directions, and copyright information, I added the strings for Hamlet and Hamilton together and then split the resulting string into a list of words.

I chose to keep punctuation attached to words for this program. This allows the resulting synthesized text to have punctuation added organically and account for which words tend to occur only after a punctuation mark. The drawback to this approach is that the sample size of the word choices is effectively reduced, because it treats “Hamilton” as completely independent from “Hamilton,” or “Hamilton!”

My program analyzed the list of words to compile a dictionary where the keys are all unique words in the two works and the results are all words that have ever immediately followed the key. In addition, I compiled a separate dictionary that analyzes each pair of consecutive words in the two works keyed to a list of words that have ever immediately followed that unique word pair. To randomly generate text, the program randomly selects an entry from the second dictionary based on the previous two generated words. If no entry exists, or if there has only been a single option for the last five consecutive selections, it instead uses the first dictionary of single words. This ensures that the program does not get into a “determinant loop” and quote word-for-word a long passage from either work that happens to have particularly unique language. 

The Donald Trump speech simulator works similarly, but it takes a string as a parameter which it prioritizes over all other options when selecting from a dictionary. For instance, if the previous two words were “I” and “am,” the dictionary entry may look like [“Donald”, “bigly”, “great”], but if “bigly” was passed as a parameter, it will select this entry rather than a random one. In this sense it can simulate themed speeches about China, walls, or emails.For this project, I used Markov chaining to emulate the style of Shakespeare’s Hamlet, the script of Hamilton: An American Musical, the two works in combination, and a collection of several Donald Trump speeches.

Because of the nature of Markov chains, I did not expect my end results to be particularly cohesive; that being said, it is much more amusing if the text created has some sort of flow or regard for syntax. In addition, especially in the case where Hamilton and Hamlet were being used collectively to create a new text, I wanted to include a sort of fail-safe feature that prevents the synthesized text from continuing for too long in a completely determinant nature, thus quoting a passage word-for-word.I felt the need to include an extra section, but I’m too lazy to write it myself. Here is a Markov chain of this report.
